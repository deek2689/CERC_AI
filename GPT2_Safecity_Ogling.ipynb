{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate transformers torch -q -U"
      ],
      "metadata": {
        "id": "_FgBqCyJpJ0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bf5eca-f762-45c7-d628-05965f396b1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HaTl_3D6pFTv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "UetfFXaQpNI_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##  DATA PATHS & HYPERPARAMETERS\n"
      ],
      "metadata": {
        "id": "9NCJSFOtpXSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'https://raw.githubusercontent.com/deek2689/CERC_AI/refs/heads/main/SafeCity%20Datasets/Ogling/train.csv'\n",
        "test_path = 'https://raw.githubusercontent.com/deek2689/CERC_AI/refs/heads/main/SafeCity%20Datasets/Ogling/test.csv'\n",
        "val_path = 'https://raw.githubusercontent.com/deek2689/CERC_AI/refs/heads/main/SafeCity%20Datasets/Ogling/dev.csv'\n",
        "batch_size = 8\n",
        "learning_rate = 5e-5\n",
        "num_epochs = 10\n",
        "patience = 2     # number of epochs to wait for improvement before stopping\n",
        "max_length = 512"
      ],
      "metadata": {
        "id": "0TfsmgNVpRbS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## READING DATA"
      ],
      "metadata": {
        "id": "KFVOcaOpprbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(train_path)\n",
        "val_data = pd.read_csv(val_path)\n",
        "test_data = pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "aSGw7qxtpnVN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-i6OFGTOy2tO",
        "outputId": "dcd1934c-896a-47e6-f918-1a738397ed4d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         Description  Category\n",
              "0  Was walking along crowded street, holding mums...         0\n",
              "1  This incident took place in the evening.I was ...         1\n",
              "2  I WAS WAITING FOR THE BUS. A MAN CAME ON A BIK...         0\n",
              "3                 Incident happened inside the train         0\n",
              "4  I witnessed an incident when a chain was bruta...         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f6af213-abf0-4526-9316-537716a4fa6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Was walking along crowded street, holding mums...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This incident took place in the evening.I was ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I WAS WAITING FOR THE BUS. A MAN CAME ON A BIK...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Incident happened inside the train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I witnessed an incident when a chain was bruta...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f6af213-abf0-4526-9316-537716a4fa6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f6af213-abf0-4526-9316-537716a4fa6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f6af213-abf0-4526-9316-537716a4fa6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ef2cd5b5-f174-4c0e-916a-9b937bb65c08\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef2cd5b5-f174-4c0e-916a-9b937bb65c08')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ef2cd5b5-f174-4c0e-916a-9b937bb65c08 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 7201,\n  \"fields\": [\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6659,\n        \"samples\": [\n          \"When i was returning from my college one old guy whistles at me near a poolchowk and did a facial expression which was very unusal.\",\n          \"Today when I was climbing up the stairs of a railway bridge, a man passed by saying 'What are you doing baby?' Makes me cringe. I've heard worse things before.\",\n          \"COmmenting\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "QDXmGEhiy7YQ",
        "outputId": "48568e01-81ac-4733-ad5e-fd773bcfb35b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Category\n",
              "0    5675\n",
              "1    1526\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPARING THE DATA"
      ],
      "metadata": {
        "id": "CdPo-l4apzFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining Instruction text\n",
        "#instruction = \"Classify if the following statement falls under ogling related to sexual harassment. The output must be a single label: 'True' or 'False'.\"\n",
        "\n",
        "def format_dataset(row):\n",
        "    \"\"\"\n",
        "    Formats the dataset into the required structure for GPT-2 training.\n",
        "    \"\"\"\n",
        "    formatted_text = (\n",
        "        #f\"### Instruction:\\n{instruction}\\n\\n\"\n",
        "        f\"### Input:\\n{row['Description']}\\n\\n\"\n",
        "        f\"### Response:\\n\"\n",
        "    )\n",
        "    label = 1 if row['Category'] == 1 else 0  # Converting category to binary\n",
        "    return formatted_text, label\n",
        "\n",
        "def process_dataset(df):\n",
        "    \"\"\"\n",
        "    Processes the data into the defined format\n",
        "    \"\"\"\n",
        "    formatted_texts = []\n",
        "    labels = []\n",
        "    for _, row in df.iterrows():\n",
        "        formatted_text, label = format_dataset(row)\n",
        "        formatted_texts.append(formatted_text)\n",
        "        labels.append(label)\n",
        "    return formatted_texts, labels\n",
        "\n",
        "# Applying the function\n",
        "formatted_texts_train, labels_train = process_dataset(train_data)\n",
        "formatted_texts_val, labels_val = process_dataset(val_data)\n",
        "formatted_texts_test, labels_test = process_dataset(test_data)\n"
      ],
      "metadata": {
        "id": "hRfKsazSp0zz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_texts_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqsLF9GvzN2e",
        "outputId": "2a79ea16-026a-4eb3-8c23-ffa504febc44"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Input:\n",
            "Was walking along crowded street, holding mums hand, when an elderly man groped butt, I turned to look at h7m and he looked away, and did it again after a while.I was 12 yrs old then.\n",
            "\n",
            "### Response:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSmR7M11zQkJ",
        "outputId": "7907c5b7-43d2-425f-d51b-2811380033c1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "qeimdkG2r_jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.bos_token  # or eos_token // Since GPT2 doesnt have a pad token\n",
        "tokenizer.padding_side = \"left\" # GPT2 being a decoder model, it uses the last token for prediction so padding on the left\n",
        "\n",
        "def tokenize_dataset(formatted_texts, labels, max_length=512):\n",
        "    tokenized = tokenizer(\n",
        "        formatted_texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = tokenized['input_ids']\n",
        "    attention_mask = tokenized['attention_mask']\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "    return TensorDataset(input_ids, attention_mask, labels_tensor)\n",
        "\n",
        "train_dataset = tokenize_dataset(formatted_texts_train, labels_train, max_length=max_length)\n",
        "val_dataset = tokenize_dataset(formatted_texts_val, labels_val, max_length=max_length)\n",
        "test_dataset = tokenize_dataset(formatted_texts_test, labels_test, max_length=max_length)\n"
      ],
      "metadata": {
        "id": "Z1sr9W8Or-Z8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATING DATALOADERS"
      ],
      "metadata": {
        "id": "hbmXVCNZsg5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "4dkuqBTYsdBx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SETTING UP DEVICE"
      ],
      "metadata": {
        "id": "6fX1CARLsnS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "eKFnu08zsqer"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf1HnTaVzfwr",
        "outputId": "6572d8c1-46b1-4105-a6cf-194b9f763dce"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL AND OPTIMIZER"
      ],
      "metadata": {
        "id": "tg9JqKL-suSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=2)\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODgxDoWYsw_C",
        "outputId": "c6a6b2d4-5be7-494f-8157-d71a4542ef18"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING - EVAL LOOP WITH EARLY STOPPING"
      ],
      "metadata": {
        "id": "e_Hnkbpqs1qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "epochs_unimproved = 0\n",
        "train_losses = [] # To store training loss after each epoch\n",
        "val_losses = [] ## Similarly for validation losses\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "  model.train()\n",
        "  total_train_loss = 0\n",
        "\n",
        "  for batch in tqdm(train_dataloader, desc = 'Training'):\n",
        "    input_ids, attention_masks, batch_labels = batch\n",
        "    input_ids, attention_masks, batch_labels = input_ids.to(device), attention_masks.to(device), batch_labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_masks,\n",
        "        labels = batch_labels\n",
        "    )\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_train_loss += loss.item()\n",
        "  avg_train_loss = total_train_loss/len(train_dataloader)\n",
        "  train_losses.append(avg_train_loss)\n",
        "  print(f\"Training Loss (Average): {avg_train_loss}\")\n",
        "\n",
        "  #Validation Loop\n",
        "  model.eval()\n",
        "  total_val_loss = 0\n",
        "  val_predictions = []\n",
        "  val_true_labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(val_dataloader, desc = 'Validation'):\n",
        "      input_ids, attention_masks, batch_labels = batch\n",
        "      input_ids, attention_masks, batch_labels = input_ids.to(device), attention_masks.to(device), batch_labels.to(device)\n",
        "      outputs = model(\n",
        "          input_ids = input_ids,\n",
        "          attention_mask = attention_masks,\n",
        "          labels = batch_labels\n",
        "      )\n",
        "      loss = outputs.loss\n",
        "      total_val_loss += loss.item()\n",
        "\n",
        "      logits = outputs.logits\n",
        "      probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "      pred_classes = torch.argmax(probs, dim=-1)\n",
        "\n",
        "      val_predictions.extend(pred_classes.cpu().numpy())\n",
        "      val_true_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "  avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "  val_losses.append(avg_val_loss)\n",
        "  val_macro_f1 = f1_score(val_true_labels, val_predictions, average = 'macro')\n",
        "  val_f1_score = f1_score(val_true_labels, val_predictions)\n",
        "\n",
        "  print(f\"  Validation loss: {avg_val_loss}\")\n",
        "  print(f\"  Validation Macro F1 score: {val_macro_f1}\")\n",
        "  print(f\"  Validation F1 score: {val_f1_score}\")\n",
        "\n",
        "  ## Early Stopping\n",
        "\n",
        "  if avg_val_loss < best_val_loss:\n",
        "    best_val_loss = avg_val_loss\n",
        "    epochs_unimproved = 0\n",
        "    torch.save(model.state_dict(), \"best_model.pt\")\n",
        "  else:\n",
        "    epochs_unimproved += 1\n",
        "    print(f\" No improvement in validation loss for {epochs_unimproved} epoch(s).\")\n",
        "    if epochs_unimproved >= patience:\n",
        "      print(\"Stopping early due to no improvement in validation loss\")\n",
        "      break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcmu-PUxs7xZ",
        "outputId": "3823ff6f-b9b1-4ccd-ed13-333f822ce803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  88%|████████▊ | 797/901 [10:34<01:22,  1.26it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the best model\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "print(\"Loaded the best model for final evaluation.\")"
      ],
      "metadata": {
        "id": "j0U9EJOIUPTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing training and validation losses"
      ],
      "metadata": {
        "id": "O5sqmQdZyBfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_losses, label='Training Loss')\n",
        "plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "plt.title(\"Training & Validation Loss by Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3JamN1SkyGUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING LOOP"
      ],
      "metadata": {
        "id": "_xCWw-Sexzn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_predictions = []\n",
        "test_true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader, desc=\"Testing\"):\n",
        "        input_ids, attention_masks, batch_labels = batch\n",
        "        input_ids, attention_masks, batch_labels = input_ids.to(device), attention_masks.to(device), batch_labels.to(device)\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_masks,\n",
        "            labels=batch_labels\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits\n",
        "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "        pred_classes = torch.argmax(probs, dim=1)\n",
        "\n",
        "        test_predictions.extend(pred_classes.cpu().numpy())\n",
        "        test_true_labels.extend(batch_labels.cpu().numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "K2vcIHATx1c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating Performance Metrics"
      ],
      "metadata": {
        "id": "0YGbz6I5x7SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_macro_f1 = f1_score(test_true_labels, test_predictions, average='macro')\n",
        "test_F1 = f1_score(test_true_labels, test_predictions)\n",
        "test_accuracy = accuracy_score(test_true_labels, test_predictions)\n",
        "test_precision = precision_score(test_true_labels, test_predictions)\n",
        "test_recall = recall_score(test_true_labels, test_predictions)\n",
        "\n",
        "print(f\"\\nTest Macro F1 score: {test_macro_f1}\")\n",
        "print(f\"Test Regular F1 score: {test_F1}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test Precision: {test_precision}\")\n",
        "print(f\"Test Recall: {test_recall}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_true_labels, test_predictions))"
      ],
      "metadata": {
        "id": "0TJZ6JuOx-2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}